{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_BirdcallRecognition_CBCDatasetOverlap_DeepFeatureExtraction.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1qM_4iveB6wT3UB_yyVdLV8fetlPIvXZX","authorship_tag":"ABX9TyOJj1ek1dbfr2u6m48dEXoX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6Gm77Gfmym_O"},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import keras\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.applications.resnet import preprocess_input, ResNet50, ResNet101\n","from keras.applications.densenet import preprocess_input, DenseNet121\n","from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n","from keras.models import Model, Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout, GlobalAveragePooling2D, Lambda\n","from tensorflow.keras.callbacks.experimental import BackupAndRestore\n","from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","from keras.models import load_model\n","import IPython.display as ipd\n","from sklearn.decomposition import PCA\n","import pickle as pkl"]},{"cell_type":"code","source":["# Retrieving Visual features files names and labels files names\n","featureFiles = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Data/\")\n","labelFiles = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Labels/\")\n","\n","for i in range(len(featureFiles)):\n","  featureFiles[i] = \"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Data/vis_feat_\" + str(i+1) + \".npy\"\n","  labelFiles[i] = \"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Labels/vis_labels_\" + str(i+1) + \".npy\"\n","\n","trainFiles, trainLabels = featureFiles, labelFiles\n","\n","print(\"Total Files = {}\".format(len(trainFiles)))\n","\n","del featureFiles\n","del labelFiles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gq6O8a9f0udS","executionInfo":{"status":"ok","timestamp":1645213999184,"user_tz":300,"elapsed":1793,"user":{"displayName":"Abhi Bhaveshkumar Amin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09984646343549019789"}},"outputId":"4590634a-8ffe-4804-a945-ea4337e9a825"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Files = 5093\n"]}]},{"cell_type":"code","source":["# Custom Generator to load batch files one by one\n","def customBatchGenerator(featureFiles, labelFiles, batchSize):\n","  for i in range(batchSize):\n","    batchX = np.load(featureFiles[i])\n","    batchY = np.load(labelFiles[i])\n","\n","    yield batchX, batchY"],"metadata":{"id":"fRfLc5LrblI1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For Shape (128, 431, 3)"],"metadata":{"id":"KI3FQ_lO3sac"}},{"cell_type":"markdown","source":["ResNet50"],"metadata":{"id":"XZiYXwiB3xUj"}},{"cell_type":"code","source":["# ResNet50 Model with pretrained ImageNet weights to extract deep features\n","\n","# Input Layer\n","input_layer = Input(shape = (128, 431, 3))\n","# Preprocess Layer\n","preprocess = Lambda(lambda x: preprocess_input(x), name='preprocess')(input_layer)\n","layer_1 = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(128, 431, 3))(preprocess)\n","# Global Average Pooling Layer\n","average = GlobalAveragePooling2D()(layer_1)\n","resnetModel = Model(inputs=input_layer, outputs=average)\n","resnetModel.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I0mMAFP-3rWz","executionInfo":{"status":"ok","timestamp":1645205558645,"user_tz":300,"elapsed":6891,"user":{"displayName":"Abhi Bhaveshkumar Amin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09984646343549019789"}},"outputId":"91e6a76e-f1ff-4990-d768-d66e3b463d33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n","94781440/94765736 [==============================] - 1s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 431, 3)]     0         \n","                                                                 \n"," preprocess (Lambda)         (None, 128, 431, 3)       0         \n","                                                                 \n"," resnet50 (Functional)       (None, 4, 14, 2048)       23587712  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n","=================================================================\n","Total params: 23,587,712\n","Trainable params: 23,534,592\n","Non-trainable params: 53,120\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["length = len(trainFiles)    # Variable to hold total number of files\n","\n","# Variables to store deep features and labels\n","features = np.zeros((length*64, 2048))\n","labels = np.zeros((length*64, 264))\n","\n","# Calling custom generator to load files one by one\n","trainBatchGenerator = customBatchGenerator(trainFiles, trainLabels, length)\n","\n","# Enumerating generator and extracting deep features of various files one by one \n","for i, data in enumerate(trainBatchGenerator):\n","  if i==0:\n","    features = resnetModel.predict(data[0])\n","    labels = data[1]\n","  else:\n","    features = np.vstack([features, resnetModel.predict(data[0])])\n","    labels = np.vstack([labels, data[1]])"],"metadata":{"id":"86pffJSw3_oL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(features.shape)\n","print(labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OpFp2SF34DZn","executionInfo":{"status":"ok","timestamp":1645213212283,"user_tz":300,"elapsed":15,"user":{"displayName":"Abhi Bhaveshkumar Amin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09984646343549019789"}},"outputId":"6a183b3d-01a3-4351-dbb8-ddddf9693bb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(325952, 2048)\n","(325952, 264)\n"]}]},{"cell_type":"code","source":["# Saving extracted deep features and labels into numpy files\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Deep Features/ResNet50_features_128.npy\", features)\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Deep Features/ResNet50_labels_128.npy\", labels)"],"metadata":{"id":"zfgkYf7P4ECO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ResNet101"],"metadata":{"id":"tXCHT0pbZZpm"}},{"cell_type":"code","source":["# ResNet101 Model with pretrained ImageNet weights to extract deep features\n","\n","# Input Layer\n","input_layer = Input(shape = (128, 431, 3))\n","# Preprocess Layer\n","preprocess = Lambda(lambda x: preprocess_input(x), name='preprocess')(input_layer)\n","layer_1 = ResNet101(include_top=False, weights=\"imagenet\", input_shape=(128, 431, 3))(preprocess)\n","# Global Average Pooling Layer\n","average = GlobalAveragePooling2D()(layer_1)\n","\n","resnetModel = Model(inputs=input_layer, outputs=average)\n","resnetModel.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPGLebqKZE7k","executionInfo":{"status":"ok","timestamp":1645214031258,"user_tz":300,"elapsed":11792,"user":{"displayName":"Abhi Bhaveshkumar Amin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09984646343549019789"}},"outputId":"38502252-811b-4e80-d3b0-9ed8120f2f97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n","171450368/171446536 [==============================] - 2s 0us/step\n","171458560/171446536 [==============================] - 2s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 431, 3)]     0         \n","                                                                 \n"," preprocess (Lambda)         (None, 128, 431, 3)       0         \n","                                                                 \n"," resnet101 (Functional)      (None, 4, 14, 2048)       42658176  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n","=================================================================\n","Total params: 42,658,176\n","Trainable params: 42,552,832\n","Non-trainable params: 105,344\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["length = len(trainFiles)    # Variable to hold total number of files\n","\n","# Variables to store deep features and labels\n","features = np.zeros((length*64, 2048))\n","labels = np.zeros((length*64, 264))\n","\n","# Calling custom generator to load files one by one\n","trainBatchGenerator = customBatchGenerator(trainFiles, trainLabels, length)\n","\n","# Enumerating generator and extracting deep features of various files one by one \n","for i, data in enumerate(trainBatchGenerator):\n","  if i==0:\n","    features = resnetModel.predict(data[0])\n","    labels = data[1]\n","  else:\n","    features = np.vstack([features, resnetModel.predict(data[0])])\n","    labels = np.vstack([labels, data[1]])"],"metadata":{"id":"6hVg8DK0ZLp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving extracted deep features into numpy file\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Deep Features/ResNet101_features_128.npy\", features)"],"metadata":{"id":"2f4CjrgrZG33"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DenseNet121"],"metadata":{"id":"pivTblZIDkv8"}},{"cell_type":"code","source":["# DenseNet121 Model with pretrained ImageNet weights to extract deep features\n","# Input Layer\n","input_layer = Input(shape = (128, 431, 3))\n","# Preprocess Layer\n","preprocess = Lambda(lambda x: preprocess_input(x), name='preprocess')(input_layer)\n","layer_1 = DenseNet121(include_top=False, weights=\"imagenet\", input_shape=(128, 431, 3))(preprocess)\n","# Global Average Pooling Layer\n","average = GlobalAveragePooling2D()(layer_1)\n","\n","densenetModel = Model(inputs=input_layer, outputs=average)\n","densenetModel.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5y7VrrI6jXB","executionInfo":{"status":"ok","timestamp":1645285023654,"user_tz":300,"elapsed":6533,"user":{"displayName":"Jay Rashmikant Patel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06576762246913309588"}},"outputId":"37da3b21-3e1e-44e8-cf49-f50d33c13616"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n","29089792/29084464 [==============================] - 0s 0us/step\n","29097984/29084464 [==============================] - 0s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 431, 3)]     0         \n","                                                                 \n"," preprocess (Lambda)         (None, 128, 431, 3)       0         \n","                                                                 \n"," densenet121 (Functional)    (None, 4, 13, 1024)       7037504   \n","                                                                 \n"," global_average_pooling2d (G  (None, 1024)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n","=================================================================\n","Total params: 7,037,504\n","Trainable params: 6,953,856\n","Non-trainable params: 83,648\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["length = len(trainFiles)    # Variable to hold total number of files\n","\n","# Variables to store deep features and labels\n","features = np.zeros((length*64, 1024))\n","labels = np.zeros((length*64, 264))\n","\n","# Calling custom generator to load files one by one\n","trainBatchGenerator = customBatchGenerator(trainFiles, trainLabels, length)\n","\n","# Enumerating generator and extracting deep features of various files one by one \n","for i, data in enumerate(trainBatchGenerator):\n","  if i==0:\n","    features = densenetModel.predict(data[0])\n","    labels = data[1]\n","  else:\n","    features = np.vstack([features, densenetModel.predict(data[0])])\n","    labels = np.vstack([labels, data[1]])"],"metadata":{"id":"8b7UlRsdD8Do"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving extracted deep features into numpy file\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Deep Features/DenseNet121_features_128.npy\", features)"],"metadata":{"id":"4WPQ8rh6EqEh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["VGG16"],"metadata":{"id":"PAvSgQX5ExDV"}},{"cell_type":"code","source":["# VGG16 Model with pretrained ImageNet weights to extract deep features\n","\n","# Input Layer\n","input_layer = Input(shape = (128, 431, 3))\n","# Preprocess Layer\n","preprocess = Lambda(lambda x: preprocess_input(x), name='preprocess')(input_layer)\n","layer_1 = VGG16(include_top=False, weights=\"imagenet\", input_shape=(128, 431, 3))(preprocess)\n","# Global Average Pooling Layer\n","average = GlobalAveragePooling2D()(layer_1)\n","\n","vggModel = Model(inputs=input_layer, outputs=average)\n","vggModel.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TGeU0gZtFGgO","executionInfo":{"status":"ok","timestamp":1645460484678,"user_tz":300,"elapsed":6674,"user":{"displayName":"Abhi Bhaveshkumar Amin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09984646343549019789"}},"outputId":"e0c1b2ce-430d-4ae8-c7af-4e994bdaccb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","58900480/58889256 [==============================] - 1s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 431, 3)]     0         \n","                                                                 \n"," preprocess (Lambda)         (None, 128, 431, 3)       0         \n","                                                                 \n"," vgg16 (Functional)          (None, 4, 13, 512)        14714688  \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["length = len(trainFiles)    # Variable to hold total number of files\n","\n","# Variables to store deep features and labels\n","features = np.zeros((length*64, 512))\n","labels = np.zeros((length*64, 264))\n","\n","# Calling custom generator to load files one by one\n","trainBatchGenerator = customBatchGenerator(trainFiles, trainLabels, length)\n","\n","# Enumerating generator and extracting deep features of various files one by one \n","for i, data in enumerate(trainBatchGenerator):\n","  if i==0:\n","    features = vggModel.predict(data[0])\n","    labels = data[1]\n","  else:\n","    features = np.vstack([features, vggModel.predict(data[0])])\n","    labels = np.vstack([labels, data[1]])"],"metadata":{"id":"e8R__H9EEzAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving extracted deep features into numpy file\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/Fall 2021/Final Project/Visual Features_abs_Overlap_RGB/Batch Data 64/Deep Features/VGG16_features_128.npy\", features)"],"metadata":{"id":"YlSXz3EaFSwz"},"execution_count":null,"outputs":[]}]}